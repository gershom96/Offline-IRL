diff --git a/src/training/train_rm_scand.py b/src/training/train_rm_scand.py
index 04dcef7..3aa3612 100644
--- a/src/training/train_rm_scand.py
+++ b/src/training/train_rm_scand.py
@@ -5,6 +5,7 @@ import sys
 import os
 import time
 import datetime
+import wandb
 from torch.utils.tensorboard import SummaryWriter
 
 sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
@@ -19,14 +20,14 @@ project_name = "Offline-IRL"
 exp_name = "SCAND_test"
 h5_file = "/fs/nexus-scratch/gershom/IROS25/Datasets/scand_preference_data.h5"
 checkpoint_dir = "/fs/nexus-scratch/gershom/IROS25/Offline-IRL/models/checkpoints"
-BATCH_SIZE = 32 # 64 = 12GB VRAM, 32 = 6.9GB VRAM
-LEARNING_RATE = 3e-4
+BATCH_SIZE = 256 
+LEARNING_RATE = 8e-4
 NUM_QUERIES = 4
 HIDDEN_DIM = 768
-N_EPOCHS = 10
+N_EPOCHS = 200
 train_val_split = 0.8
 num_workers = 4
-batch_print_freq = 10
+batch_print_freq = 5
 gradient_log_freq = 100
 notes = "implementing wandb"
 use_wandb = True
@@ -61,7 +62,6 @@ now = datetime.datetime.now()
 timestamp = now.strftime("%Y-%m-%d %H:%M:%S")
 run_name = f"{exp_name}__{timestamp}"
 if use_wandb:
-    import wandb
     wandb.init(
         project=project_name,
         notes=notes,
@@ -77,7 +77,7 @@ writer.add_text(
 )
 
 # Define Model, Loss, Optimizer
-model = RewardModelSCAND(num_queries=NUM_QUERIES, hidden_dim=HIDDEN_DIM).to(device)
+model = RewardModelSCAND(num_queries=NUM_QUERIES).to(device)
 criterion = PL_Loss()
 optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
 scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)
@@ -123,7 +123,7 @@ for epoch in range(N_EPOCHS):
 
         if batch_count % batch_print_freq == 0:  # Log every 10 batches
             SPS = global_step / (time.time() - start_time)
-            print(f"Epoch [{epoch+1}/{N_EPOCHS}] | Batch {batch_count} | Train Loss: {loss.item():.4f}, steps per second: {SPS:.3f}")
+            print(f"Epoch [{epoch+1}/{N_EPOCHS}] | Batch {batch_count} | Train Loss: {loss.item():.4f}, steps per second: {SPS:.3f} | LR: {optimizer.param_groups[0]['lr']}")
             writer.add_scalar("charts/SPS", SPS, global_step)
             writer.add_scalar("epoch", epoch, global_step)
 
diff --git a/src/utils/__pycache__/reward_model_scand.cpython-310.pyc b/src/utils/__pycache__/reward_model_scand.cpython-310.pyc
index 377cdbf..4077cdd 100644
Binary files a/src/utils/__pycache__/reward_model_scand.cpython-310.pyc and b/src/utils/__pycache__/reward_model_scand.cpython-310.pyc differ
diff --git a/src/utils/reward_model_scand.py b/src/utils/reward_model_scand.py
index f4f8620..f65b4ea 100644
--- a/src/utils/reward_model_scand.py
+++ b/src/utils/reward_model_scand.py
@@ -97,7 +97,7 @@ class RewardModelSCAND(nn.Module):
             nn.Linear(256, 128),
             nn.GELU(),
             nn.Linear(128, 1),
-            nn.Tanh()  # Normalize output range
+            # nn.Tanh()  # Normalize output range
         )
 
         self._initialize_weights()
